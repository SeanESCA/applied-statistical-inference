---
title: "MA40198 Coursework"
author: "Group 13: Sean Soon and Shaveen Colambage"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries 

<!--
Your declared libraries should be included in this code chunk.
-->

```{r}
library(rlang)
```



# Part I

```{r}
load(url("https://people.bath.ac.uk/kai21/ASI/data/CW24/dataQ1.RData"))
```

## Question 1.1

```{r Q1.1}
P2_optim_1 <- P2_optim_2 <- P2_optim_3 <- P2_optim_4 <- vector("list", 5)
names(P2_optim_1) <- names(P2_optim_2) <- names(P2_optim_3) <- names(P2_optim_4) <- c("mle","negloglik","gradient","hessian","AIC")

P2_optim_1
```

```{r deriv_pack}
deriv_pack = function(func_expr, 
                      namevec = c("alpha", "beta", "theta"),
                      data_arg_vec = c("x", "y"),
                      theta_init = rep(1, 3)) {
  deriv_res <- deriv(
    func_expr,
    namevec = namevec,
    function.arg = c(namevec, data_arg_vec)
  )
  
  fn <- function(theta = theta_init, data_list = list("x" = 1, "y" = 1), apply.sum = T) {
    theta_list = as.list(theta)
    names(theta_list) = namevec
    aux  <- do.call(deriv_res, c(theta_list, data_list))
    if(apply.sum) {
      sum(as.numeric(aux))
    } else {
      c(aux)
    } 
  }
  
  gr <- function(theta = theta_init, data_list = list("x" = 1, "y" = 1), apply.sum = T) {
    theta_list = as.list(theta)
    names(theta_list) = namevec
    aux  <- do.call(deriv_res, c(theta_list, data_list))
    if(apply.sum) {
      apply(attr(aux, "gradient"), 2, sum)
    } else {
      attr(aux, "gradient")
    }
  }
  
  list(fn = fn, gr = gr)
}
``` 

```{r fit_optim}
fit_optim <- function(par_len, nll_pack, data, mean = 0, sd = 10, 
                      method = "BFGS", hessian = T, N_samples = 100, 
                      seed = 3141592){
  
  # set.seed(seed)
  # use set.seed for reproducibility purposes only. But always better to try without it and then settle at the end for reproducibility
  
  fit <- vector("list", length = N_samples)
  for (i in 1:N_samples){
    
    stop_crit <-T
    
    #tries until it finds an optimisation with no upfront error . this guarantees 'N_samples' optimisation are done
    
    while(stop_crit){
      
      # sometimes initial point is too far, which throws an straight error, hence the use of 'try'
      fit[[i]] <- try( 
        optim(par = rnorm(par_len, mean = mean, sd = sd),
              fn  = nll_pack$fn,
              gr  = nll_pack$gr,
              data_list = data,
              method  = method ,
              hessian = hessian),
        silent = F) # this supresses the red error messages
      
      if(inherits(fit[[i]], "try-error")){
        
        stop_crit <-T # if error, tries again
        
      } else {
        
        stop_crit <-F # if no error, continues to next step
      }
    }
    
    # check for numerical convergence first 
    no_convergence <- fit[[i]]$convergence > 0
    
    # checks if asymptotic variances are possible to obtain
    no_variance <- inherits(try(solve(fit[[i]]$hessian),
                                silent = T), 
                            "try-error")
    
    null_variance <- F
    NA_variance   <- F
    
    if (!no_variance){
      # checks if asymptotic variance are NaN
      NA_variance <- as.logical(sum(is.nan(diag(solve(fit[[i]]$hessian)))))
      
      if(!NA_variance){
        # checks if asymptotic variance are zero up to machine precision
        null_variance <- as.logical(sum(diag(solve(fit[[i]]$hessian))< .Machine$double.eps ^ 0.5))
      }
    }
    
    fail <- no_variance | no_convergence | NA_variance | null_variance 
    if (fail){
      fit[[i]]$value <- NA
    }
    
  } 
  
  extract_negloglik <- function(optim_object){
    optim_object$value
  }
  # selects the optimisation with minimum negative loglikelihood
  nll_vals <- lapply(X = fit, FUN = extract_negloglik)
  fit[[which.min(nll_vals)]] # return the final selected optimisation
}
```

```{r aic}
aic = function(nll_pack, opt_res, data = dataQ1) {
  par = opt_res$par
  2 * (nll_pack$fn(par, data) + length(par))
}
```

```{r}
set_P2_optim = function(P2_optim, nll_pack, opt_res) {
  P2_optim$mle = c(opt_res$par[1:2], exp(opt_res$par[3]))
  P2_optim$negloglik = opt_res$value
  P2_optim$hessian = opt_res$hessian
  P2_optim$gradient = nll_pack$gr(opt_res$par, dataQ1)
  P2_optim$AIC = aic(nll_pack, opt_res)
  P2_optim
}
```
For all four models, $sigma$ was reparameterised as $e^{\theta}$.

```{r P2_optim_1, message=FALSE, warning=FALSE}
nll_expr_q1_1 = expr(0.5 * log(2 * pi) + theta + alpha + beta * x + 
                       0.5 * (y - exp(alpha + beta * x)) ^ 2 / 
                       exp(2 * (theta + alpha + beta * x)))
nll_pack_q1_1 = deriv_pack(nll_expr_q1_1)
opt_res_q1_1 = fit_optim(3, nll_pack_q1_1, dataQ1)
set_P2_optim(P2_optim_1, nll_pack_q1_1, opt_res_q1_1)
```

```{r P2_optim_2, message=FALSE, warning=FALSE}
nll_expr_q1_2 = expr(0.5 * log(2 * pi) + theta + 
                       0.5 * (log(y) - alpha - beta * x) ^ 2 / exp(2 * theta))
nll_pack_q1_2 = deriv_pack(nll_expr_q1_2)
opt_res_q1_2 = fit_optim(3, nll_pack_q1_2, dataQ1)
set_P2_optim(P2_optim_2, nll_pack_q1_2, opt_res_q1_2)
```

```{r P2_optim_3, message=FALSE, warning=FALSE}
z_expr_q1_3 = expr((log(y) - alpha - beta * x) / exp(theta))
nll_expr_q1_3 = expr(!!z_expr_q1_3 + 2 * log((1 + exp(-!!z_expr_q1_3))) + theta)
nll_pack_q1_3 = deriv_pack(nll_expr_q1_3)
opt_res_q1_3 = fit_optim(3, nll_pack_q1_3, dataQ1)
set_P2_optim(P2_optim_3, nll_pack_q1_3, opt_res_q1_3)
```

```{r P2_optim_4, message=FALSE, warning=FALSE}
nll_expr_q1_4 = expr(-log(log(2)) - theta + exp(theta) * (alpha + beta * x) + (1 - exp(theta)) * log(y) + log(2) * (y / exp(alpha + beta * x)) ^ exp(theta))
nll_pack_q1_4 = deriv_pack(nll_expr_q1_4)
opt_res_q1_4 = fit_optim(3, nll_pack_q1_4, dataQ1)
set_P2_optim(P2_optim_4, nll_pack_q1_4, opt_res_q1_4)
```

Therefore, model 3 is the best based on the AIC.

## Question 1.2

```{r Q1.2}
n_grid     <- 1000 
x          <- seq(1, 15, length=n_grid)
P2_bands_1 <- P2_bands_2 <- 
  P2_bands_3 <- P2_bands_4 <- matrix(NA,nrow=n_grid,ncol=3)
colnames(P2_bands_1) <- colnames(P2_bands_2) <- 
  colnames(P2_bands_3) <- colnames(P2_bands_4) <- c("lower","est","upper")
head(P2_bands_1)
```

```{r set P2_bands}
set_P2_bands = function(P2_bands, opt_res) {
  temp = P2_bands
  S <- solve(opt_res$hessian) 
  for (i in 1:n_grid){
    vec.x <- c(1, x[i])
    est <- crossprod(vec.x, opt_res$par[1:2])
    se <- sqrt(crossprod(vec.x, S[1:2, 1:2]) %*% vec.x)
    temp[i,] <- exp(c(est - 1.96 * se, est, est + 1.96 * se))
  }
  temp
}
```

```{r plot_P2_bands}
plot_bands = function(bands, data, main) {
  plot(data, pch = 19, main = main)
  lines(x, bands[, 2], col = "red")
  lines(x, bands[, 1], col = "red", lty = 2)
  lines(x, bands[, 3], col = "red", lty = 2)
}
```

```{r P2_bands_1}
P2_bands_1 = set_P2_bands(P2_bands_1, opt_res_q1_1)
plot_bands(P2_bands_1, dataQ1, 
           main = paste(c("Plot of the median and its 95% confidence",
                         "interval (CI) for model 1 against x")))
```

```{r P2_bands_2}
P2_bands_2 = set_P2_bands(P2_bands_2, opt_res_q1_2)
plot_bands(P2_bands_2, dataQ1, 
           main = "Plot of the median for model 2 against x")
```

```{r P2_bands_3}
P2_bands_3 = set_P2_bands(P2_bands_3, opt_res_q1_3)
plot_bands(P2_bands_3, dataQ1,
           main = "Plot of the median for model 3 against x")
```

```{r P2_bands_4}
P2_bands_4 = set_P2_bands(P2_bands_4, opt_res_q1_4)
plot_bands(P2_bands_4, dataQ1,
           main = "Plot of the median for model 4 against x")
```
# Part II

```{r}
#run to save the data frame 'dataQ2'  on to the R environment
load(url("https://people.bath.ac.uk/kai21/ASI/data/CW24/dataQ2.RData"))
```



## Question 2.1

```{r Q2.1_setup}
P21_optim_1 <- P21_optim_2 <- P21_optim_3 <- P21_optim_full <- vector("list", 5)
names(P21_optim_1) <- names(P21_optim_2) <- names(P21_optim_3) <- names(P21_optim_full) <- c("mle","negloglik","gradient","hessian","NIC")

P21_optim_1
```
```{r nic}
nic = function(nll_pack, opt_res, data = dataQ2) {
  aux = nll_pack$gr(opt_res$par, data, apply.sum = F)
  K_hat = t(aux) %*% aux
  2 * (opt_res$value + sum(diag(solve(opt_res$hessian) %*% K_hat)))
}
```

For $\mathcal{F}_{\text{full}}$, $\phi$ is reparameterised as $e^{\theta}$.

```{r P21_optim_full, message=FALSE, warning=FALSE}
nll_expr_q2_full = expr(lgamma(exp(-theta)) - 
                          exp(-theta) * (log(alpha + beta * x) - theta) + 
                          (1 - exp(-theta)) * log(y) + 
                          exp(-theta) * (alpha + beta * x) * y)
nll_pack_q2_full = deriv_pack(nll_expr_q2_full)
opt_res_q2_full = fit_optim(3, nll_pack_q2_full, dataQ2)
P21_optim_full$mle = c(opt_res_q2_full$par[1:2], exp(opt_res_q2_full$par[3]))
P21_optim_full$negloglik = opt_res_q2_full$value
P21_optim_full$hessian = opt_res_q2_full$hessian
P21_optim_full$gradient = nll_pack_q2_full$gr(opt_res_q2_full$par, dataQ2)
P21_optim_full$NIC = nic(nll_pack_q2_full, opt_res_q2_full)
P21_optim_full
```

```{r P21_optim_1, message=FALSE, warning=FALSE}
nll_expr_q2_1 = expr(lgamma(exp(-theta1)) - 
                       exp(-theta1) * (log(theta1 - x * theta1 ^ 2) - theta1) +
                       (1 - exp(-theta1)) * log(y) + 
                       exp(-theta1) * (theta1 - x * theta1 ^ 2) * y)
nll_pack_q2_1 = deriv_pack(nll_expr_q2_1,
                           c("theta1"),
                           theta_init = 2)
opt_res_q2_1 = fit_optim(1, nll_pack_q2_1, dataQ2)
P21_optim_1$mle = opt_res_q2_1$par
P21_optim_1$negloglik = opt_res_q2_1$value
P21_optim_1$hessian = opt_res_q2_1$hessian
P21_optim_1$gradient = nll_pack_q2_1$gr(opt_res_q2_1$par, dataQ2)
P21_optim_1$NIC = nic(nll_pack_q2_1, opt_res_q2_1)
P21_optim_1
```

```{r P21_optim_2}
nll_expr_q2_2 = expr(lgamma(exp(-theta2)) - 
                       exp(-theta2) * (log(theta2 + tau2 * x) - theta2) + 
                       (1 - exp(-theta2)) * log(y) + 
                       exp(-theta2) * (theta2 + tau2 * x) * y)
nll_pack_q2_2 = deriv_pack(nll_expr_q2_2,
                           c("theta2", "tau2"),
                           theta_init = rep(1, 2))
opt_res_q2_2 = fit_optim(2, nll_pack_q2_2, dataQ2)
P21_optim_2$mle = opt_res_q2_2$par
P21_optim_2$negloglik = opt_res_q2_2$value
P21_optim_2$hessian = opt_res_q2_2$hessian
P21_optim_2$gradient = nll_pack_q2_2$gr(opt_res_q2_2$par, dataQ2)
P21_optim_2$NIC = nic(nll_pack_q2_2, opt_res_q2_2)
P21_optim_2
```

For $\mathcal{F}_{3}$, $\delta_{3}$ is reparametrised as $\exp(\theta_{4})$.

```{r P21_optim_3}
nll_expr_q2_3 = expr(lgamma(exp(-theta4)) - 
                       exp(-theta4) * (log(theta3 - x * theta3 ^ 2) - theta4) + 
                       (1 - exp(-theta4)) * log(y) + 
                       exp(-theta4) * (theta3 - x * theta3 ^ 2) * y)
nll_pack_q2_3 = deriv_pack(nll_expr_q2_3,
                           c("theta3", "theta4"),
                           theta_init = rep(2, 2))
opt_res_q2_3 = fit_optim(2, nll_pack_q2_3, dataQ2)
P21_optim_3$mle = c(opt_res_q2_full$par[1], exp(opt_res_q2_full$par[2]))
P21_optim_3$negloglik = opt_res_q2_3$value
P21_optim_3$hessian = opt_res_q2_3$hessian
P21_optim_3$gradient = nll_pack_q2_3$gr(opt_res_q2_3$par, dataQ2)
P21_optim_3$NIC = nic(nll_pack_q2_3, opt_res_q2_3)
P21_optim_3
```

$\mathcal{F}_{\text{full}}$ is the best based on the NIC.

## Question 2.2 

```{r Q2.2}
n_grid     <- 1000 
x          <- seq(0, 1, length=n_grid)
P22_bands_1 <- P22_bands_2 <- 
  P22_bands_3 <- P22_bands_full <- matrix(NA,nrow=n_grid,ncol=3)
colnames(P22_bands_1) <- colnames(P22_bands_2) <- 
  colnames(P22_bands_3) <- colnames(P22_bands_full) <- c("lower","est","upper")

head(P22_bands_1)
```

```{r P22_bands}
S_full <- solve(opt_res_q2_full$hessian)  
S_2 <- solve(opt_res_q2_2$hessian)
S_3 <- solve(opt_res_q2_3$hessian)

theta1 <- opt_res_q2_1$par
theta3 <- opt_res_q2_3$par[1]
est_3 <- 1 / (theta3 - x * theta3 ^ 2)

for (i in 1:n_grid){
  vec.x <- c(1, x[i])
  est_full <- crossprod(vec.x, opt_res_q2_full$par[1:2])
  se_full <- sqrt(crossprod(vec.x, S_full[1:2, 1:2]) %*% vec.x)
  P22_bands_full[i,] <- 1/c(est_full + 1.96 * se_full, 
                         est_full, 
                         est_full - 1.96 * se_full) 
  
  est_2 <- crossprod(vec.x, opt_res_q2_2$par[1:2])
  se_2 <- sqrt(crossprod(vec.x, S_2[1:2, 1:2]) %*% vec.x)
  P22_bands_2[i,] <- 1/c(est_2 + 1.96 * se_2, 
                         est_2, 
                         est_2 - 1.96 * se_2)
  
  vec.x_3 <- c((1 - 2 * theta3 * x[i]) * est_3[i] ^ 2, 0)
  se_3 <- sqrt(crossprod(vec.x_3, S_3) %*% vec.x_3)
  P22_bands_3[i,] <- c(est_3[i] - 1.96 * se_3, 
                         est_3[i], 
                         est_3[i] + 1.96 * se_3)
}

est_1 <- 1/(theta1 - x * theta1 ^ 2)
se_1 <- abs(1 - 2 * opt_res_q2_1$par * x) / c(opt_res_q2_1$hessian ^ 0.5) * est_1 ^ 2
P22_bands_1[, 1] <- est_1 - 1.96 * se_1
P22_bands_1[, 2] <- est_1
P22_bands_1[, 3] <- est_1 + 1.96 * se_1
```

```{r plot_P22_bands}
plot_bands(P22_bands_full, dataQ2,
           main = "Plot of the mean for the full model")
plot_bands(P22_bands_1, dataQ2,
           main = "Plot of the mean and 95% CI for model 1")
plot_bands(P22_bands_2, dataQ2,
           main = "Plot of the mean for model 2")
plot_bands(P22_bands_3, dataQ2,
           main = "Plot of the mean for model 3")
```

## Question 2.3


```{r Q2.3}
# use the following matrices to place the CI limits and estimates

n_grid     <- 1000 
x          <- seq(0,1,length=n_grid)
P23_bands_1 <- P23_bands_2 <- 
  P23_bands_3 <- P23_bands_full <- matrix(NA,nrow=n_grid,ncol=3)
colnames(P23_bands_1) <- colnames(P23_bands_2) <- 
  colnames(P23_bands_3) <- colnames(P23_bands_full) <- c("lower","est","upper")

head(P23_bands_1)
```


## Question 2.4


```{r Q2.4}
# use the following matrices to place the CI limits and estimates

n_grid     <- 1000 
x          <- seq(0,1,length=n_grid)
P24_bands_1 <- P24_bands_2 <- 
  P24_bands_3 <- P24_bands_full <- matrix(NA,nrow=n_grid,ncol=3)
colnames(P24_bands_1) <- colnames(P24_bands_2) <- 
  colnames(P24_bands_3) <- colnames(P24_bands_full) <- c("lower","est","upper")

head(P24_bands_1)
```


# References

<!-- Here you should list the external references consulted if other than the course resources-->

1. Item 1

2.  Item 1
